---
format: 
  revealjs:
    embed-resources: false
    theme: [brand, styling.scss]
    width: 1280
    height: 720
eval: false
---

## {background-image="Big_Data_Tiny_Laptop.png" background-size="contain" background-color='{{< brand color lightgrey >}}'}

# Hi, I'm Javier {background-color='{{< brand color blue >}}'}

## Career & Skills Progression

<br>

:::: {layout="[[1,1], [1]]"}

::: {#finance}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  id[****FINANCIAL MODELING****]

  classDef bluedrawn fill:#c0e5fe,stroke:#612200,color:#000000;
  class id bluedrawn;
```

:::
:::

::: {#datascience}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  id2[****DATA SCIENCE****]

  classDef peachdrawn fill:#ffddd6,stroke:#612200,color:#000000;
  class id2 peachdrawn;
```

:::
:::

::: {#career}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  A[EY] --> B[PG&E]
  B --> C[KPMG]
  C --> D{UCI's<br>MSBA<br>Program}
  D --> E[Centene]
  E --> F[Bloomreach]
  F --> G[Centene]

  classDef whitedrawn fill:#ffffff,stroke:#612200,color:#000000;
  class A,B,C,D,E,F,G whitedrawn;
```

:::
:::

::::

::: footer
[Personal Site](https://www.javierorracadeatcu.com/): JavierOrracaDeatcu.com | [LinkedIn](https://www.linkedin.com/in/orraca/): linkedin.com/in/orraca
:::

## Career & Skills Progression

<br>

:::: {layout="[[1,1], [1]]"}

::: {#finance}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  id[**FINANCIAL MODELING**]

  classDef bluedrawn fill:#c0e5fe,stroke:#612200,color:#000000;
  class id bluedrawn;
```

:::
:::

::: {#datascience}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  id2[**DATA SCIENCE**]

  classDef peachdrawn fill:#ffddd6,stroke:#612200,color:#000000;
  class id2 peachdrawn;
```

:::
:::

::: {#career}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  A[EY] --> B[PG&E]
  B --> C[KPMG]
  C --> D{UCI's<br>MSBA<br>Program}
  D --> E[Centene]
  E --> F[Bloomreach]
  F --> G[Centene]

  classDef bluedrawn fill:#c0e5fe,stroke:#612200,color:#000000;
  classDef whitedrawn fill:#ffffff,stroke:#612200,color:#000000;
  class A,B,C bluedrawn;
  class D,E,F,G whitedrawn;
```

:::
:::

::::

::: footer
[Personal Site](https://www.javierorracadeatcu.com/): JavierOrracaDeatcu.com | [LinkedIn](https://www.linkedin.com/in/orraca/): linkedin.com/in/orraca
:::

## Career & Skills Progression

<br>

:::: {layout="[[1,1], [1]]"}

::: {#finance}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  id[**FINANCIAL MODELING**]

  classDef bluedrawn fill:#c0e5fe,stroke:#612200,color:#000000;
  class id bluedrawn;
```

:::
:::

::: {#datascience}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  id2[**DATA SCIENCE**]

  classDef peachdrawn fill:#ffddd6,stroke:#612200,color:#000000;
  class id2 peachdrawn;
```

:::
:::

::: {#career}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  A[EY] --> B[PG&E]
  B --> C[KPMG]
  C --> D{UCI's<br>MSBA<br>Program}
  D --> E[Centene]
  E --> F[Bloomreach]
  F --> G[Centene]

  classDef bluedrawn fill:#c0e5fe,stroke:#612200,color:#000000;
  classDef peachdrawn fill:#ffddd6,stroke:#612200,color:#000000;
  classDef whitedrawn fill:#ffffff,stroke:#612200,color:#000000;
  class A,B,C bluedrawn;
  class D whitedrawn;
  class E,F,G peachdrawn;
```

:::
:::

::::

::: footer
[Personal Site](https://www.javierorracadeatcu.com/): JavierOrracaDeatcu.com | [LinkedIn](https://www.linkedin.com/in/orraca/): linkedin.com/in/orraca
:::

## Career & Skills Progression

<br>

:::: {layout="[[1,1], [1], [1]]"}

::: {#finance}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  id[**FINANCIAL MODELING**]

  classDef bluedrawn fill:#c0e5fe,stroke:#612200,color:#000000;
  class id bluedrawn;
```

:::
:::

::: {#datascience}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  id2[**DATA SCIENCE**]

  classDef peachdrawn fill:#ffddd6,stroke:#612200,color:#000000;
  class id2 peachdrawn;
```

:::
:::

::: {#career}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  A[EY] --> B[PG&E]
  B --> C[KPMG]
  C --> D{UCI's<br>MSBA<br>Program}
  D --> E[Centene]
  E --> F[Bloomreach]
  F --> G[Centene]
  
  classDef bluedrawn fill:#c0e5fe,stroke:#612200,color:#000000;
  classDef peachdrawn fill:#ffddd6,stroke:#612200,color:#000000;
  classDef whitedrawn fill:#ffffff,stroke:#612200,color:#000000;
  class A,B,C bluedrawn;
  class D whitedrawn;
  class E,F,G peachdrawn;
```

:::
:::

::: {#skills}
::: {style="text-align: center"}
```{mermaid}
%%| eval: true
---
config:
  look: handDrawn
---

flowchart LR
  A[Excel, PowerPoint, Access, SQL] --> B{UCI's<br>MSBA<br>Program}
  B --> C[Automating Manual Excel Work]
  C --> D[Developing R Packages & Web Apps]
  B --> E[Code-based Analytics]
  E --> F[Machine Learning & AI]
  F --> G[R, Linux, git, Posit tools, Databricks]

  classDef bluedrawn fill:#c0e5fe,stroke:#612200,color:#000000;
  classDef peachdrawn fill:#ffddd6,stroke:#612200,color:#000000;
  classDef whitedrawn fill:#ffffff,stroke:#612200,color:#000000;
  class A,C bluedrawn;
  class D,E,F,G peachdrawn;
  class B whitedrawn;
```

:::
:::

::::

::: footer
[Personal Site](https://www.javierorracadeatcu.com/): JavierOrracaDeatcu.com | [LinkedIn](https://www.linkedin.com/in/orraca/): linkedin.com/in/orraca
:::


## Standing Out with Shiny

<br>

:::: {layout="[[100], [60,40]]"}

::: {#shiny}
::: {style="text-align: left"}

- Shiny is a [code-based web app framework]{.fragment .highlight-green} for Python and R

- *Easy-ish-ly* build web apps with no formal web dev experience

:::
:::

::: {#shinyleft_text}
::: {style="text-align: left"}

- Use [reactive programming]{.fragment .highlight-green} that allows for dynamic, real-time updates to the app based on user input

- Extend your Shiny apps with HTML widgets, [real-time data polling]{.fragment .highlight-green}, JavaScript, CSS, and more

:::
:::

::: {#shinyright_image}
::: {style="text-align: left"}

![Image: © Analythium](images/shiny_structure.png){fig-align="left"}

:::
:::

::::

::: footer
Learn more about [Shiny for Python](https://shiny.posit.co/py/) and [Shiny for R](https://shiny.posit.co/r/)
:::


## Shiny Demo as a Resume Accessory

<br>

- Most [corporate dashboards feel clunky...]{.fragment .highlight-green}

- They're laggy, very boxy, e.g., Power BI, Tableau, MicroStrategy

- Dashboards typically struggle with fast, real-time calculations, search, and data manipulation capabilities

- [For hiring teams, you can use Shiny as a resume accessory]{.fragment .highlight-green} to demonstrate how easy it is to develop **and** deploy a web app styled with the company’s brand aesthetics

::: footer
Check out my blog post: [Impressing Hiring Teams with a Shiny App Demo (2023-03-28)](https://www.javierorracadeatcu.com/posts/2023-03-28-shiny-bslib-socal-rug/2023-03-28-shiny-bslib-socal-rug)
:::


## Shiny Demo as a Resume Accessory

*Bloomreach's website:*

![Image: © 2025 Bloomreach, Inc.](images/bloomreach_site.png){height="50%" width="50%" fig-align="center"}

::: footer
Check out my blog post: [Impressing Hiring Teams with a Shiny App Demo (2023-03-28)](https://www.javierorracadeatcu.com/posts/2023-03-28-shiny-bslib-socal-rug/2023-03-28-shiny-bslib-socal-rug)
:::


## Shiny Demo as a Resume Accessory

*Javier's Shiny demo:*

![](images/shiny_app_demo.gif){height="70%" width="70%" fig-align="center"}

::: footer
Launch this live Shiny app demo: <https://javierorraca.shinyapps.io/Bloomreach_Shiny_App>
:::


## Pro Tip! 💡 *Shiny Assistant*

<br>

- The new Shiny Assistant... 🤯... An LLM-powered tool that builds functional Python and R Shiny apps in minutes!
<br><br>
- Shiny Assistant builds apps using [Shinylive](https://github.com/posit-dev/shinylive), a web interface made possible by [WebAssembly](https://webassembly.org/) (or "wasm") 
<br><br>
- The LLM’s training data is a few months old as of this writing so it won't know about the latest Shiny features

::: footer
Posit's [Shiny Assistant blog](https://shiny.posit.co/blog/posts/shiny-assistant/) post | Try the [Shiny Assistant](https://gallery.shinyapps.io/assistant/) for yourself!
:::


## My Professional Data Science Workflow

<br>

![](images/data_science_process.png){fig-align="center"}

::: footer
*R for Data Science, 2nd Edition* by Wickham, Çetinkaya-Rundel, & Grolemund | <https://r4ds.hadley.nz>
:::


## My Professional Data Science Toolkit

<br>

![Image: © Posit Software, PBC.](images/rstudio_ide.png){height="70%" width="70%" fig-align="center"}

::: footer
Learn more about the open-source RStudio IDE | <https://posit.co/products/open-source/rstudio>
:::


## My Professional Data Science Toolkit

![Image: © Posit Software, PBC.](images/rstudio-panes-labeled.jpeg){height="55%" width="55%" fig-align="center"}

::: footer
RStudio User Guide | <https://docs.posit.co/ide/user/ide/get-started>
:::


## My Professional Data Science Toolkit

![](images/connect_concept-map.png){height="75%" width="75%" fig-align="center"}

::: footer
Learn about Posit [Professional Products & Solutions](https://solutions.posit.co/get-started) |  Deploy your content on Posit's beta [Connect Cloud](https://connect.posit.cloud/)!
:::


## Typical Python Tools for Data Science

![](images/vs_code.png){height="65%" width="65%" fig-align="center"}

::: footer
Learn about Microsoft's Virtual Studio Code ("VS Code") User Interface | <https://code.visualstudio.com/docs/getstarted/userinterface>
:::


## Typical Python Tools for Data Science

![](images/jupyter_notebook.png){height="50%" width="50%" fig-align="center"}

::: footer
Image: © Ander Fernández Jauregui | Learn about Project Jupyter's [Jupyter Notebook](https://jupyter.org)
:::


## In Review

<br>

- RStudio IDE's "always on" panes welcomed R users seeking a data-analysis-first experience

- [For Python users, RStudio felt too R-centric]{.fragment .highlight-green} and other tools worked *just fine* including VS Code, Jupyter Notebooks, PyCharm, etc.

- There are many programming languages that can be used for data analysis, [but Python and R are the de facto standards for data science]{.fragment .highlight-green}


## {background-color='{{< brand color yellow >}}'}

::: r-fit-text
So, why isn't there
:::

::: r-fit-text
*one tool*
:::


## {.center background-color='{{< brand color yellow >}}'}

::: r-fit-text
to rule them all!?
:::


##

<br>

![](images/tobias.gif){height="60%" width="60%" fig-align="center"}

::: footer
Me, using RStudio while my teammates use VS Code...
:::

# Introducing: Positron™ {background-color='{{< brand color blue >}}'}

## Positron, *it looks familiar!*

![](images/positron.png){fig-align="center"}

::: footer
Visit the new Positron website to learn more | <https://positron.posit.co/>
:::


## About Positron

- What is Positron? From Posit's getting started docs:

> - A next-generation data science IDE built by Posit PBC
> - An extensible, polyglot tool for writing code and exploring data
> - A familiar environment for reproducible authoring and publishing

- Positron is [a tailor-made IDE for data science]{.fragment .highlight-green} built on top of [Code OSS](https://github.com/microsoft/vscode) that can be used with any combination of programming languages 

::: footer
Visit the new Positron website to learn more | <https://positron.posit.co/>
:::


## VS Code OSS w/ RStudio panes!

![](images/positron-panes.svg){fig-align="center"}

::: footer
Layout by Dr. Athanasia Mo Mowinckel | [Positron IDE - A new IDE for data science](https://drmowinckels.io/blog/2024/positron/)
:::


## Prerequisites {.smaller}

<br>

- **Windows** prereqs:
  <br><br>
  - Ensure the latest [Visual C++ Redistributable](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-microsoft-visual-c-redistributable-version) is installed
  <br><br>
  - If you're an R user package developer, note that Positron doesn't currently bundle `Rtools`.
  <br><br>
  - For reference, `RTools` contains the required compilers needed to build R packages from source code on Windows

::: footer
Getting Started with Positron | [Machine Prerequisites](https://positron.posit.co/start.html)
:::


## Prerequisites {.smaller}

<br>

- **Python** prereqs:
  <br><br>
  - The Posit team recommends [pyenv](https://github.com/pyenv/pyenv) to manage Python versions, and Python versions from 3.8 to 3.12 are actively supported on Positron
  <br><br>
  - For Linux users, install the SQLite system libraries (`sqlite-devel` or `libsqlite3-dev`) ahead of time so `pyenv` can build your Python version(s) of choice
  <br><br>
  - Positron communicates with Python via the `ipykernel`
  <br><br>
  - If you're using `venv` or `conda` to manage your Python projects, you can install `ipykernal` manually as follows: `python3 -m pip install ipykernel`

::: footer
Getting Started with Positron | [Machine Prerequisites](https://positron.posit.co/start.html)
:::


## Prerequisites {.smaller}

<br>

- **R** prereqs:
  <br><br>
  - Positron requires R 4.2 or higher - To install R, follow the instructions for your OS at <https://cloud.r-project.org>
  <br><br>
  - If you’d like to have multiple R installations, [rig](https://github.com/r-lib/rig) is a great tool that works on macOS, Windows and Linux, and works well with Positron

::: footer
Getting Started with Positron | [Machine Prerequisites](https://positron.posit.co/start.html)
:::


## Interpreter Selector {.smaller}

<br>

:::: {.columns}

::: {.column width="60%"}
- When Positron starts for the first time in a new workspace (or project directory), it will start Python and/or R depending on your workspace characteristics
<br><br>
- In subsequent runs, [Positron will start the same interpreter(s) that was running the last time]{.fragment .highlight-green} that you used that workspace
<br><br>
- You can start, stop, and switch interpreters from the interpreter selector
:::

::: {.column width="40%"}
![](images/interpreter_selector.png){width="393px" height="330px" fig-align="center"}
:::

::::

::: footer
Getting Started with Positron | [Interpreter Selection](https://positron.posit.co/interpreters.html)
:::


## Key Bindings & Command Palette {.smaller}

- Key bindings trigger actions by pressing a combination of keys
- The key binding <kbd>Cmd</kbd>/<kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>P</kbd> will bring up Positron's Command Palette
- This lets you search and execute actions without needing to remember the key binding

![](images/command_palette.png){width="75%" height="75%" fig-align="center"}

<br>

::: footer
Learn more on Emil Hvitfeldt's blog post [Positron: My Key Bindings](https://emilhvitfeldt.com/post/positron-key-bindings/)
:::


## Global Keyboard Shortcuts {.smaller}

<br>

| Shortcut | Description |
| -------- | ----------- |
| <kbd>Cmd/Ctrl</kbd>+<kbd>Enter</kbd> | Run the selected code in the editor; if no code is selected, run the current statement | 
| <kbd>Cmd/Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>0</kbd> | Restart the interpreter currently open in the Console | 
| <kbd>Cmd/Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>Enter</kbd> | Run the file open in the editor (using e.g. `source()` or `%run`) | 
| <kbd>F1</kbd> | Show contextual help for the topic under the cursor |
| <kbd>Cmd/Ctrl</kbd>+<kbd>K</kbd>, <kbd>Cmd/Ctrl</kbd>+<kbd>R</kbd> | Show contextual help for the topic under the cursor (alternate binding) |
| <kbd>Cmd/Ctrl</kbd>+<kbd>K</kbd>, <kbd>F</kbd> | Focus the Console |
| <kbd>Ctrl</kbd>+<kbd>L</kbd> | Clear the Console |

::: footer
Positron docs | [Keyboard Shortcuts](https://positron.posit.co/keyboard-shortcuts.html)
:::


## R Keyboard Shortcuts {.smaller}

<br>

| Shortcut | Description |
| -------- | ----------- |
| <kbd>Cmd/Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>M</kbd> | Insert the pipe operator (`|>` or `%>%`) | 
| <kbd>Alt</kbd>+<kbd>-</kbd> | Insert the assignment operator (`<-`) |
| <kbd>Cmd/Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>L</kbd> | Load the current R package, if any | 
| <kbd>Cmd/Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>B</kbd> | Build and install the current R package, if any | 
| <kbd>Cmd/Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>T</kbd> | Test the current R package, if any | 
| <kbd>Cmd/Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>E</kbd> | Check the current R package, if any | 
| <kbd>Cmd/Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>D</kbd> | Document the current R package, if any | 

::: footer
Positron docs | [Keyboard Shortcuts](https://positron.posit.co/keyboard-shortcuts.html)
:::


## RStudio Keymap {.smaller}

<br>

If you're an experienced RStudio user, you can [easily set the RStudio keybindings]{.fragment .highlight-green} in the Positron settings:

- Open Positron's settings in the UI or the keystroke <kbd>Cmd/Ctrl</kbd>+<kbd>,</kbd>
- Search for "keymap", or navigate to *Extensions > RStudio Keymap*
- Check the "Enable RStudio key mappings for Positron" checkbox

::: footer
Positron docs | [Keyboard Shortcuts](https://positron.posit.co/keyboard-shortcuts.html)
:::


## Data Explorer Overview {.smaller}

<br>

- The new [Data Explorer allows for interactive exploration]{.fragment .highlight-green} of various types of dataframes using Python (`pandas`, `polars`) or R (`data.frame`, `tibble`, `data.table`, `polars`)
<br><br>
- The Data Explorer has three primary components
  - **Data grid**: Spreadsheet-like display of the data with sorting
  - **Summary panel**: Column name, type and missing data percentage for each column
  - **Filter bar**: Ephemeral filters for specific columns

::: footer
Positron docs | [Data Explorer](https://positron.posit.co/data-explorer.html)
:::


## Data Explorer Overview {.smaller}

<br>

- To use, navigate to the Variables Pane and click on the Data Explorer icon:

![](images/data-explorer-variables.png){width="70%" height="70%" fig-align="center"}

::: footer
Positron docs | [Data Explorer](https://positron.posit.co/data-explorer.html)
:::


## Data Explorer Overview

![](images/data-explorer.png){width="80%" height="80%" fig-align="center"}

::: footer
Positron docs | [Data Explorer](https://positron.posit.co/data-explorer.html)
:::


## Data Explorer's *Data Grid* {.smaller}

<br>

:::: {.columns}

::: {.column width="60%"}
- The data grid is the primary display and [scales efficiently]{.fragment .highlight-green} with large in-memory datasets up to millions of rows or columns
<br><br>
- At the top right of each column, there is a context menu that [controls sorting and filtering]{.fragment .highlight-green} in the selected column
:::

::: {.column width="5%"}
:::

::: {.column width="35%"}
![](images/data-grid-menu.png){fig-align="center"}
:::

::::

::: footer
Positron docs | [Data Explorer](https://positron.posit.co/data-explorer.html)
:::


## Data Explorer's *Summary Panel* {.smaller}

<br>

:::: {.columns}

::: {.column width="60%"}
- Displays a vertical scrolling list of all columns in the data
<br><br>
- It [displays a sparkline histogram of that column’s data]{.fragment .highlight-green}, displays the amount of missing data, and shows some summary statistics about that column
<br><br>
- Double clicking on a column name will bring the column into focus in the data grid
:::

::: {.column width="40%"}
![](images/data-explorer-summary-panel.png){fig-align="center"}
:::

::::

::: footer
Positron docs | [Data Explorer](https://positron.posit.co/data-explorer.html)
:::


## Data Explorer's *Filter Bar* {.smaller}

<br>

:::: {.columns}

::: {.column width="40%"}
- The filter bar has controls to add filters, show/hide existing filters, or clear filters
<br><br>
- Clicking the <kbd>+</kbd> button quickly adds a new filter
<br><br>
- The status bar at the bottom of the Data Explorer also displays the percentage and number of remaining rows relative to the original total after applying a filter
:::

::: {.column width="60%"}
![](images/data-explorer-filter-ui.png){fig-align="center"}
:::

::::

::: footer
Positron docs | [Data Explorer](https://positron.posit.co/data-explorer.html)
:::


## Connections Pane {.smaller}

:::: {.columns}

::: {.column width="35%"}
<br>
- [Explore database connections]{.fragment .highlight-green} established with ODBC drivers or packages
<br><br>
- For Python users, the `sqlite3` and `SQLAlchemy` packages are supported
<br><br>
- For R users, the `odbc`, `sparklyr`, `bigrquery`, and more packages are supported
:::

::: {.column width="65%"}
![](images/connections-pane.png){fig-align="center"}
:::

::::

::: footer
Positron docs | [Connections Pane](https://positron.posit.co/connections-pane.html)
:::


## Interactive Apps {.smaller}

:::: {.columns}

::: {.column width="35%"}
<br>
- Instead of running apps from a Terminal, Positron lets you run supported apps by clicking the <kbd>Play</kbd> button in Editor Actions
<br><br>
- [Supported apps include the following: Shiny, Dash, FastAPI, Flask, Gradio, and Streamlit]{.fragment .highlight-green}
<br><br>
- You can also start apps in Debug mode
:::

::: {.column width="65%"}
![](images/run-app-button.png){fig-align="center"}
:::

::::

::: footer
Positron docs | [Run Interactive Apps](https://positron.posit.co/run-interactive-apps.html)
:::

## Learn More about Positron 

{{< video https://youtu.be/8uRcB34Hhsw?si=AlSxeWoMzx0g9QlL width="100%" height="85%" >}}

::: footer
Visit Posit's new [Positron website](https://positron.posit.co) and their [YouTube channel](https://www.youtube.com/@PositPBC/videos) to learn more
:::

## Special Bonus for R Users 😘 {.smaller}

<br>

:::: {.columns}

::: {.column width="60%"}
- Ark ("an R kernel") was created to serve as the interface between R and the Positron IDE and is a Jupyter kernel, a Language Server Protocol ("LSP") server, and it is a Debug Adapter Protocol ("DAP")
<br><br>
- It is compatible with all frontends implementing the Jupyter protocol and is bundled with Positron
<br><br>
- Ark's LSP was written with a Rust backend to future proof its ability to perform sophisticated static analysis of R code and its DAP allows for advanced step-debugging
:::

::: {.column width="40%"}
![](images/ark_logo.png){width="75%" height="75%" fig-align="center"}
:::

::::

::: footer
Learn more about Ark on the [Ark GitHub repo](https://github.com/posit-dev/ark)
:::

## {.center background-color='{{< brand color peach >}}'}

::: r-fit-text
So, lesson learned...<br>
Positron = Amazing.
:::

## {.center background-color='{{< brand color peach >}}'}

::: r-fit-text
But next...
:::

::: r-fit-text
let's talk about
:::

<!-- ## {.center background-color='{{< brand color peach >}}'}

::: r-fit-text
let's talk about
::: -->

## {.center background-color='{{< brand color peach >}}'}

::: r-fit-text
ULTRA
:::

## {.center background-color='{{< brand color peach >}}'}

::: r-fit-text
FAST
:::

## {.center background-color='{{< brand color peach >}}'}

::: r-fit-text
ETL 💨
:::

## {.center background-color='{{< brand color peach >}}'}

![](images/jake_the_dog.gif){fig-align="center"}

# Arrow, DuckDB, and Polars {background-color='{{< brand color blue >}}'}

## About these Frameworks {.smaller}

<br>

- **Apache Arrow**: An in-memory columnar format that lets data move quickly between systems and languages (like Python and R) and speeds up analytical tasks
<br><br>
- **DuckDB**: An in-process SQL database management system focused on analytical query processing
<br><br>
- **Polars**: A modern DataFrame library with a multi-threaded query engine written in Rust that uses the Apache Arrow memory model under the hood
<br><br>

. . .

- [**Apache Parquet**: A popular columnar storage format that compresses data to save space and is easily read by Arrow, DuckDB, and Polars for efficient data querying]{.fragment .highlight-green}

::: footer
Learn more about [Apache Arrow](https://arrow.apache.org/), [DuckDB](https://duckdb.org/), [Polars](https://pola.rs/), and [Apache Parquet](https://parquet.apache.org/)
:::


## Benefits & Use Cases {.smaller}

<br>

- These frameworks provide [convenient methods for reading and writing columnar file formats]{.fragment .highlight-green}
<br><br>
- If you're working with a collection of `.parquet` files, the Arrow packages for C++, Python, and R support [reading entire directories of files and treating them as a single dataset]{.fragment .highlight-green} 
<br><br>
- Allows zero-copy data sharing inside a single process without any build-time or link-time dependency requirements. This allows, for example, R users to access Python `pyarrow`-based projects using R's `reticulate` package.
<br><br>
- Apache Spark uses Arrow as a data interchange format, and both Python's `PySpark` and R's `sparklyr` take advantage of Arrow for significant performance gains when transferring data

::: footer
Learn more about [Apache Arrow](https://arrow.apache.org/), [DuckDB](https://duckdb.org/), [Polars](https://pola.rs/), and [Apache Parquet](https://parquet.apache.org/)
:::


## Installing Arrow, DuckDB, and Polars

:::: {.columns}

::: {.column width="49%"}

*Python*

```{python}
#| eval: false
#| echo: true

# Arrow env vars for AWS S3 & GCP support
import os
os.environ["LIBARROW_MINIMAL"] = "FALSE"
os.environ["ARROW_S3"] = "ON"
os.environ["ARROW_GCS"] = "ON"

# Install packages
!pip install pyarrow duckdb polars

```

:::

::: {.column width="2%"}
:::

::: {.column width="49%"}

*R*

```{r}
#| eval: false
#| echo: true

# Arrow env vars for AWS S3 & GCP support
Sys.setenv(LIBARROW_MINIMAL = "false")
Sys.setenv(ARROW_S3 = "ON")
Sys.setenv(ARROW_GCS = "ON")

# Enable Polars install with pre-built
# Rust library binary 
Sys.setenv(NOT_CRAN = "true")

# Install packages
install.packages(c("arrow", "duckdb"))
install.packages("polars", repos = "https://community.r-multiverse.org")
install.packages("polarssql", repos = "https://rpolars.r-universe.dev")
```
:::

::::

::: footer
Installation Guides: Apache Arrow ([Python](https://arrow.apache.org/docs/python/install.html), [R](https://arrow.apache.org/docs/r/)), DuckDB ([Python](https://duckdb.org/docs/guides/python/install.html), [R](https://r.duckdb.org/)), Polars ([Python](https://docs.pola.rs/user-guide/installation/), [R](https://pola-rs.github.io/r-polars/vignettes/install.html))
:::


## Back to fast... *How fast?*

- My personal laptop is a [MacBook Air with 24 GB RAM]{.fragment .highlight-green}
- To test Arrow's capabilities, I read a [40 GB dataset]{.fragment .highlight-green} with more than [1.1 billion rows and 24 columns]{.fragment .highlight-green}
- The `.parquet` dataset was partitioned by Year and Month (120 files)
- Important to note that my laptop would not be able to load this object entirely into memory as a data.frame or tibble given my laptop's limited RAM

::: footer
Arrow | Learn more at <https://arrow.apache.org/>
:::


## Reading Remote Parquet Data {.smaller}

:::: {.columns}

::: {.column width="49%"}

*Python*

```{python}
#| eval: false
#| echo: true

import pyarrow.dataset as ds
import pyarrow.compute as pc
import os

# Set path for download
# NYC Taxi Data download (40 GB)
data_path = os.path.join("data", "nyc-taxi")

# Open connection to the remote dataset
nyc_dataset = ds.dataset(
  "s3://voltrondata-labs-datasets/nyc-taxi", 
  format = "parquet"
)

# Filter for years 2012 - 2021
filtered_table = nyc_dataset.to_table(
    filter = ds.field("year").isin(list(range(2012, 2022)))
)

# Write out the filtered data, partitioned by year and month
ds.write_dataset(
    filtered_table,
    base_dir = data_path,
    format = "parquet",
    partitioning = ["year", "month"]
)
```

:::

::: {.column width="2%"}
:::

::: {.column width="49%"}

*R*

```{r}
#| eval: false
#| echo: true

library(here)
library(arrow)
library(dplyr)

# Set path for download
# NYC Taxi Data download (40 GB)
data_path <- here::here("data/nyc-taxi")

# Open connection to the remote dataset,
# filter for years 2012 - 2021, and
# write out the filtered data,
# partitioned by year and month
open_dataset("s3://voltrondata-labs-datasets/nyc-taxi") |>
  filter(year %in% 2012:2021) |> 
  write_dataset(data_path, partitioning = c("year", "month"))
```

:::

::::

::: footer
Arrow | Learn more at <https://arrow.apache.org/>
:::

## Benchmarking Read Times

*R*

```{r}
#| eval: false
#| echo: true

library(ggplot2)
library(bench)

# Benchmark Read Times
bnch <- bench::mark(
  min_iterations = 1000,
  arrow = arrow::open_dataset(here::here("data/nyc-taxi"))
)

autoplot(bnch)
```

::: footer
Arrow | Learn more at <https://arrow.apache.org/>
:::

## Benchmarking Read Times

- Once "locally" available, the 40GB, 1.1 billion row dataset (benchmarked 1,000 times) can be [read on average in 17ms]{.fragment .highlight-green}

![](images/plot_arrow_read.png){width="55%" fig-align="center"}

::: footer
Arrow | Learn more at <https://arrow.apache.org/>
:::

## Benchmarking Data Manipulation

- Using R's `dplyr`, we can perform ETL on an `arrow` table and `collect()` the results back to a df

```{r}
#| eval: false
#| echo: true

# Open Arrow connection to dataset (40 GB)
nyc_taxi <- open_dataset(here::here("data/nyc-taxi"))

# Benchmark dplyr pipeline
bnch <- bench::mark(
  min_iterations = 100,
  arrow = nyc_taxi |> 
    filter(payment_type %in% c("Credit card", "Cash")) |> 
    group_by(payment_type) |> 
    summarise(mean_fare = mean(fare_amount, na.rm = T),
              mean_tip = mean(tip_amount, na.rm = T)) |> 
    ungroup() |> 
    dplyr::collect()
)

autoplot(bnch)
```

::: footer
Arrow | [Arrow + dplyr compatibility](https://r4ds.hadley.nz/arrow.html)
:::

## Benchmarking ETL

- The results show the ETL pipeline [on average summarized 1.1 billion rows in 9.5s]{.fragment .highlight-green}, benchmarked over 100 iterations

![](images/plot_arrow_summarise.png){width="55%" fig-align="center"}

::: footer
Arrow | [Arrow + dplyr compatibility](https://r4ds.hadley.nz/arrow.html)
:::

## Note for R's Tidyverse Users

- Many functions from the tidyverse collections of packages have 1:1 compatibility with Arrow tables
- However, sometimes you'll encounter a breaking point
- Take this `stringr::str_replace_na()` example:
<br><br>
```{r}
#| echo: true
#| code-line-numbers: "1-4|3-4"
nyc_taxi |> 
  mutate(vendor_name = str_replace_na(vendor_name, "No vendor"))
#> Error: Expression str_replace_na(vendor_name, "No vendor") 
#> not supported in Arrow
```

. . .

- Out of the box, Arrow does not support `stringr::str_replace_na()`

::: footer
Arrow | [Arrow + dplyr compatibility](https://r4ds.hadley.nz/arrow.html)
:::

## 

![](images/tobias.gif){height="60%" width="60%" fig-align="center"}

::: footer
Me, struggling to use my favorite `tidyverse` functions with Arrow...
:::

## {.center background-color='{{< brand color blue >}}'}

::: r-fit-text
but wait!
:::

::: r-fit-text
*a solution exists*
:::

## User Defined Functions

- Arrow allows users to create and register User Defined Functions (or "UDFs") to the Arrow engine
- Almost any function can be made Arrow-friendly by registering custom UDFs to the Arrow kernel
- Let's learn how to register `stringr::str_replace_na()` with the Arrow kernel

::: footer
Arrow | Learn more about registering Arrow [User Defined Functions ("UDFs")](https://arrow.apache.org/docs/r/reference/register_scalar_function.html)
:::

## Registering UDFs

- First, run `arrow::schema()` on your Arrow table to review the field name and data type pairs

```{r}
#| echo: true
#| code-line-numbers: "1-10|3"
arrow::schema(nyc_taxi)
#> Schema
#> vendor_name: string
#> pickup_datetime: timestamp[ms]
#> dropoff_datetime: timestamp[ms]
#> passenger_count: int64
#> trip_distance: double
#> pickup_longitude: double
#> pickup_latitude: double
#> ...
```

- Since I want to mutate the `vendor_name` field, I know I'll be working with an Arrow `string()` data type

::: footer
Arrow | Learn more about registering Arrow [User Defined Functions ("UDFs")](https://arrow.apache.org/docs/r/reference/register_scalar_function.html)
:::

## Registering UDFs

- Next, we'll use `arrow::register_scalar_function()`
- Name your UDF `replace_arrow_nas`
- If you're registering a tidyverse function, set `auto_convert = TRUE`

```{r}
#| echo: true
#| code-line-numbers: "1-13|3-4|3-4,12"
arrow::register_scalar_function(
  name = "replace_arrow_nas",
  # Note: The first argument must always be context
  function(context, x, replacement) {
    stringr::str_replace_na(x, replacement)
  },
  in_type = schema(
    x = string(),
    replacement = string()
  ),
  out_type = string(),
  auto_convert = TRUE
)
```

::: notes
Unless you're developing a package, `auto_convert` should be set to `TRUE`
:::

::: footer
Arrow | Learn more about registering Arrow [User Defined Functions ("UDFs")](https://arrow.apache.org/docs/r/reference/register_scalar_function.html)
:::

## Trying the UDF {auto-animate="true"}

- Let's see if the registered `replace_arrow_nas()` Arrow UDF works...

```{r}
#| echo: true
nyc_taxi |> 
  mutate(vendor_name = replace_arrow_nas(vendor_name, "No vendor")) |> 
  distinct(vendor_name) |> 
  arrange(vendor_name) |> 
  collect()
```

::: footer
Arrow | Learn more about registering Arrow [User Defined Functions ("UDFs")](https://arrow.apache.org/docs/r/reference/register_scalar_function.html)
:::


## Trying the UDF {auto-animate="true"}

- Let's see if the registered `replace_arrow_nas()` Arrow UDF works...

```{r}
#| echo: true
nyc_taxi |> 
  mutate(vendor_name = replace_arrow_nas(vendor_name, "No vendor")) |> 
  distinct(vendor_name) |> 
  arrange(vendor_name) |> 
  collect()

#> # A tibble: 3 × 1
#>   vendor_name
#>   <chr>      
#> 1 CMT
#> 2 No vendor
#> 3 VTS
```

. . .

- *Success! It works!*

::: footer
Arrow | Learn more about registering Arrow [User Defined Functions ("UDFs")](https://arrow.apache.org/docs/r/reference/register_scalar_function.html)
:::

##

![](images/pokemon.gif){fig-align="center"}

::: footer
Eevee can't believe it... "Wooooooooooow, Javi!"
:::


## DuckDB {.smaller}

<br><br>
- [DuckDB Labs](https://duckdblabs.com/) created an in-line database management system, like a SQLite database engine, but optimized for distributed compute and optimized for larger-than-memory analysis
<br><br>
- The `duckdb` package for Python offers a state-of-the-art optimizer that pushes down filters and projections directly into Arrow scans
<br><br>
- As a result, only relevant columns and partitions will be read thus significantly accelerates query execution
<br><br>
- DuckDB comes with core and community extensions that expand the framework to, e.g., scan remote Databricks Unity Catalog tables without needing to spin up a Spark cluster

::: footer
DuckDB Labs | Learn about [DuckDB](https://duckdb.org) and [DuckDB Extensions](https://duckdb.org/docs/extensions/overview.html)
:::


## DuckDB Usage Basics

:::: {.columns}

::: {.column width="49%"}

*Python*

```{python}
#| eval: false
#| echo: true
import duckdb

# Connect to an in-memory DuckDB instance and scan
# the Parquet data set to make a temp View
con = duckdb.connect()

con.execute("""
    CREATE VIEW nyc_taxi AS
    SELECT * FROM read_parquet('data/nyc-taxi/**/*.parquet', hive_partitioning=true)
""")

# Run your SQL query
df = con.execute("""
    SELECT 
        payment_type,
        AVG(fare_amount) AS mean_fare,
        AVG(tip_amount)  AS mean_tip
    FROM nyc_taxi
    WHERE payment_type IN ('Credit card', 'Cash')
    GROUP BY payment_type
""").df()

print(df)
```
:::

::: {.column width="2%"}
:::

::: {.column width="49%"}

*R*

```{r}
#| eval: false
#| echo: true
library(duckdb)

# Connect to an in-memory DuckDB instance and scan
# the Parquet data set to make a temp View
con <- dbConnect(duckdb())

dbExecute(con, "
  CREATE VIEW nyc_taxi AS 
  SELECT * FROM read_parquet('data/nyc-taxi/**/*.parquet', hive_partitioning = true)"
)

# Run your SQL query
df <- dbGetQuery(con, "
    SELECT 
        payment_type,
        AVG(fare_amount) AS mean_fare,
        AVG(tip_amount)  AS mean_tip
    FROM nyc_taxi
    WHERE payment_type IN ('Credit card', 'Cash')
    GROUP BY payment_type
")

print(df)
```
:::

::::


::: footer
DuckDB Labs | Learn how [DuckDB quacks Arrow](https://duckdb.org/2021/12/03/duck-arrow.html)
:::


## DuckDB Streaming with Python

::: panel-tabset
## DuckDB

```{r}
#| eval: false
#| echo: true
# DuckDB via Python
# Open dataset using year,month folder partition
nyc = ds.dataset('nyc-taxi/', partitioning=["year", "month"])

# Get database connection
con = duckdb.connect()

# Run query that selects part of the data
query = con.execute("SELECT total_amount, passenger_count,year FROM nyc where total_amount > 100 and year > 2014")

# Create Record Batch Reader from Query Result.
# "fetch_record_batch()" also accepts an extra parameter related to the desired produced chunk size.
record_batch_reader = query.fetch_record_batch()

# Retrieve all batch chunks
chunk = record_batch_reader.read_next_batch()
while len(chunk) > 0:
    chunk = record_batch_reader.read_next_batch()
```

## Pandas

```{python}
#| eval: false
#| echo: true
# We must exclude one of the columns of the NYC dataset due to an unimplemented cast in Arrow
working_columns = ["vendor_id","pickup_at","dropoff_at","passenger_count","trip_distance","pickup_longitude",
    "pickup_latitude","store_and_fwd_flag","dropoff_longitude","dropoff_latitude","payment_type",
    "fare_amount","extra","mta_tax","tip_amount","tolls_amount","total_amount","year", "month"]

# Open dataset using year,month folder partition
nyc_dataset = ds.dataset(dir, partitioning=["year", "month"])
# Generate a scanner to skip problematic column
dataset_scanner = nyc_dataset.scanner(columns=working_columns)

# Materialize dataset to an Arrow Table
nyc_table = dataset_scanner.to_table()

# Generate Dataframe from Arow Table
nyc_df = nyc_table.to_pandas()

# Apply Filter
filtered_df = nyc_df[
    (nyc_df.total_amount > 100) &
    (nyc_df.year >2014)]

# Apply Projection
res = filtered_df[["total_amount", "passenger_count","year"]]

# Transform Result back to an Arrow Table
new_table = pa.Table.from_pandas(res)
```
:::

::: footer
DuckDB Labs | Learn how [DuckDB quacks Arrow](https://duckdb.org/2021/12/03/duck-arrow.html)
:::

## DuckDB Streaming Speed Bump {.smaller}


- The Python `pandas` runtime was 146.91 seconds

. . .

- Python's `duckdb` runtime was 0.05 seconds

. . .

- Data manipulation [processing time was 2,900x faster]{.fragment .highlight-green} with `duckdb` vs `pandas`

. . .

![](images/minion.gif){width="60%" fig-align="center"}

::: footer
DuckDB Labs | Learn how [DuckDB quacks Arrow](https://duckdb.org/2021/12/03/duck-arrow.html)
:::

## For R users: duckplyr

- `duckplyr`, from DuckDB Labs, offers 1:1 compatibility with `dplyr` functions but there are some caveats:
    - Factor columns, nested lists, and nested tibbles are not *yet* supported
    - To group data, use `dplyr`'s `summarize()` function with the `.by` argument as `group_by()` is not be supported

::: footer
duckplyr | Learn more at <https://duckdblabs.com/>
:::

## Polars

![](images/about_polars.png){fig-align="center"}

::: footer
polars | Learn more at <https://pola.rs/>
:::

## Polars

- While Arrow is primarily a memory format and data transfer standard, Polars is specifically designed for data analysis with lazy evaluation, DataFrame manipulations, and a consistent API across languages
<br><br>
- DuckDB is a full database system that excels at SQL queries and can integrate with both Arrow and Polars, but Polars focuses on in-memory processing and programmatic data manipulation

::: footer
polars | Learn more at <https://pola.rs/>
:::


## Benchmarking Analysis

- Arrow and DuckDB really stood out for fast manipulation of data using `dplyr` syntax
- The SQL below shows the basic transformation done to the data using `dplyr`, `arrow`, `duckdb`, `duckplyr`, and `polars`

```{sql}
#| eval: false
#| echo: true
SELECT 
    payment_type,
    AVG(fare_amount) AS mean_fare,
    AVG(tip_amount)  AS mean_tip
FROM nyc_taxi
WHERE payment_type IN ('Credit card', 'Cash')
GROUP BY payment_type;
```

::: footer
DuckDB Labs | Learn more at <https://duckdblabs.com/>
:::

## Benchmark: 1 million rows

![](images/benchmark_1000000.png){fig-align="center"}

::: footer
DuckDB Labs | Learn more at <https://duckdblabs.com/>
:::

## Benchmark: 10 million rows

![](images/benchmark_10000000.png){fig-align="center"}

::: footer
DuckDB Labs | Learn more at <https://duckdblabs.com/>
:::

## Benchmark: 100 million rows

![](images/benchmark_100000000.png){fig-align="center"}

::: footer
DuckDB Labs | Learn more at <https://duckdblabs.com/>
:::

## Benchmark: 500 million rows

![](images/benchmark_500000000.png){fig-align="center"}

::: footer
DuckDB Labs | Learn more at <https://duckdblabs.com/>
:::

## Benchmark: 1.1 billion rows

![](images/benchmark_1100000000.png){fig-align="center"}

::: footer
DuckDB Labs | Learn more at <https://duckdblabs.com/>
:::


##

![](images/wrap_it_up.gif){fig-align="center"}


# Quarto {background-color='{{< brand color blue >}}'}

## {.center background-color='{{< brand color blue >}}'}

::: r-fit-text
Just to clarify...
:::


## {.center background-color='{{< brand color blue >}}'}

::: r-fit-text
It's *Quarto*.
:::

. . .

::: r-fit-text
Q-U-A-R-T-O.
:::


## {.center background-color='{{< brand color blue >}}'}

::: r-fit-text
Not #4 in Spanish (or "cuatro").
:::


## Quarto Presentations {.smaller}

<br>

- These web slides were built with [Quarto](https://quarto.org/)!
<br><br>
- [Quarto is an open-source scientific and technical publishing system]{.fragment .highlight-green} that can be used with Python, R, [Julia](https://julialang.org/), and [Observable JS](https://observablehq.com/@observablehq/observable-javascript)
<br><br>
- Similar to Jupyter Notebook `.ipynb` files (and in many ways, the successor to R Markdown `.Rmd`), Quarto lets you [develop static and interactive reproducible, production quality content]{.fragment .highlight-green} including articles, presentations, dashboards, websites, blogs, and books in HTML, PDF, MS Word, ePub, and more
<br><br>
- In addition to custom styling with `.css` or `.scss`, the new `_brand.yml` file can be used with your Quarto and Shiny projects to provide a unifying and portable branding framework  

::: footer
Learn more about [Quarto](https://quarto.org/) and [brand.yml](https://posit-dev.github.io/brand-yml/) | Posit blog post: [Unified branding across Posit tools with brand.yml](https://posit.co/blog/unified-branding-across-posit-tools-with-brand-yml/)
:::


## Quarto Presentations

- The following sections were copied almost entirely from Quarto's Reveal.js demo documentation

- The next few slides cover what you can do with Quarto and [Reveal.js](https://revealjs.com) including:
  - Presenting code and LaTeX equations
  - Rendering code chunk computations in slide output
  - Fancy transitions, animations, and code windows

::: footer
Quarto | Learn more on Quarto's Reveal.js [demo presentation](https://github.com/quarto-dev/quarto-web/blob/main/docs/presentations/revealjs/demo/index.qmd)
:::

## Pretty Code {auto-animate="true"}

- Over 20 syntax highlighting themes available
- Default theme optimized for accessibility

``` r
# Define a server for the Shiny app
function(input, output) {
  
  # Fill in the spot we created for a plot
  output$phonePlot <- renderPlot({
    # Render a barplot
  })
}
```

::: footer
Quarto | [Syntax Highlighting](https://quarto.org/docs/output-formats/html-code.html#highlighting)
:::

## Code Animations {auto-animate="true"}

- Over 20 syntax highlighting themes available
- Default theme optimized for accessibility

``` r
# Define a server for the Shiny app
function(input, output) {
  
  # Fill in the spot we created for a plot
  output$phonePlot <- renderPlot({
    # Render a barplot
    barplot(WorldPhones[,input$region]*1000, 
            main=input$region,
            ylab="Number of Telephones",
            xlab="Year")
  })
}
```

::: footer
Quarto | [Code Animations](https://quarto.org/docs/presentations/revealjs/advanced.html#code-animations)
:::

## Line Highlighting

- Highlight specific lines for emphasis
- Incrementally highlight additional lines

``` {.python code-line-numbers="4-5|7|10"}
import numpy as np
import matplotlib.pyplot as plt

r = np.arange(0, 2, 0.01)
theta = 2 * np.pi * r
fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})
ax.plot(theta, r)
ax.set_rticks([0.5, 1, 1.5, 2])
ax.grid(True)
plt.show()
```

::: footer
Quarto | [Line Highlighting](https://quarto.org/docs/presentations/revealjs/#line-highlighting)
:::

## LaTeX Equations

- To include a LaTeX equation in Quarto, you would use the double dollar sign delimiters ($$) for a display equation on a separate line, like this:

- `$$x = \frac{-b \pm \sqrt{(b^2 - 4ac)}}{2a}$$`

$$x = \frac{-b \pm \sqrt{(b^2 - 4ac)}}{2a}$$

::: footer
Quarto | [LaTeX Equations](https://quarto.org/docs/output-formats/html-basics.html#latex-equations)
:::

## Counters

Great for training purposes or when you've got a time limit

::: columns
::: {.column width="50%"}

```{r}
#| eval: false
#| echo: true

# YOUR TURN! Complete the below 
# dplyr pipeline to group by and
# summarize the data set

library(dplyr)
data(package = "ggplot2", "diamonds")

diamonds |> 
  <your code here>
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
#| echo: true
#| code-fold: true
#| code-summary: "See {countdown} code"
library(countdown)
countdown(
  minutes = 0, 
  seconds = 10,
  play_sound = TRUE,
  color_border = "#1A4064",
  color_text = "#76AADB",
  font_size = "3em"
)
```
:::
:::

```{r}
#| eval: true
#| echo: false
library(countdown)
countdown(
  minutes = 0, 
  seconds = 10,
  right = "55%", 
  bottom = "5%",
  play_sound = TRUE,
  color_border = "#FFDDD6",
  color_text = "#ff3a12",
  font_size = "3em"
)
```

::: footer
Quarto | Learn more about the [countdown](https://pkg.garrickadenbuie.com/countdown/) package
:::

## {.center background-color='{{< brand color peach >}}'}

::: r-fit-text
*Thank you!* 🤍
:::

# questions? {.center background-color='{{< brand color blue >}}'}

<br><br>

Connect with me!

- Personal Site: [JavierOrracaDeatcu.com](https://www.javierorracadeatcu.com/){style="color: black"}
- LinkedIn: [linkedin.com/in/orraca](https://www.linkedin.com/in/orraca/){style="color: black"}